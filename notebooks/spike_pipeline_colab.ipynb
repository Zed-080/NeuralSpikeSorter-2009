{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3c5bcd",
   "metadata": {},
   "source": [
    "<u><b>The Code below is to be ran in colab and so magic commands (!,%)  won't work in a normal notebook:</b></u>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512fab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 1. GPU Setup\n",
    "# -------------------------------------------------------------\n",
    "!nvidia-smi\n",
    "#or fallback:\n",
    "# import subprocess\n",
    "# subprocess.run([\"nvidia-smi\"])\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Setup Google Drive and Change Working Directory\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 1. Mount Drive first\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Change the current working directory (CWD) to the desired location\n",
    "# ‚ö†Ô∏è This path must exist!\n",
    "NOTEBOOK_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
    "%cd $NOTEBOOK_DIR\n",
    "print(f\"Current Working Directory set to: {os.getcwd()}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Pull Latest Repo\n",
    "# -------------------------------------------------------------\n",
    "# !git clone now executes inside the NOTEBOOK_DIR\n",
    "!git clone \"https://github.com/Zed-080/NeuralSpikeSorter-2009.git\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Switch focus to repo and Install Dependencies\n",
    "# -------------------------------------------------------------\n",
    "# The folder is now inside your Drive, so the path is longer:\n",
    "%cd NeuralSpikeSorter-2009\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# or fallback:\n",
    "# subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "\n",
    "# or manually:\n",
    "# !pip install numpy scipy scikit-learn tensorflow matplotlib   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2292f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 5. Run Scripts (Live Logging Execution)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Note: The 'drive.mount' and '%cd NeuralSpikeSorter-2009' steps\n",
    "# must be run successfully in earlier cells.\n",
    "\n",
    "# !python main_train.py\n",
    "\n",
    "!python -c \"from main_train import main; main(pretest=False)\"\n",
    "\n",
    "!python main_infer.py\n",
    "\n",
    "# LOG_FILE = \"run_log.txt\"\n",
    "# print(f\"Running and capturing console output live to: {LOG_FILE}\")\n",
    "\n",
    "# # Use redirection and 'tee' to display output LIVE while also writing to the file.\n",
    "\n",
    "# # 1. Clear the file and run training command\n",
    "# # The (2>&1) ensures both stdout and stderr are passed to tee.\n",
    "# # The '| tee {LOG_FILE}' creates (or overwrites) the file.\n",
    "# !echo \"--- TRAINING START: $(date) ---\" | tee {LOG_FILE}\n",
    "# !python -c \"from main_train import main; main(pretest=True)\" 2>&1 | tee -a {LOG_FILE}\n",
    "\n",
    "# # 2. Run inference (append to file)\n",
    "# # The '| tee -a {LOG_FILE}' appends the output to the existing file.\n",
    "# !echo \"--- INFERENCE START: $(date) ---\" | tee -a {LOG_FILE}\n",
    "# !python -c \"from main_infer import main_infer; main_infer()\" 2>&1 | tee -a {LOG_FILE}\n",
    "\n",
    "# !echo \"--- RUN END: $(date) ---\" | tee -a {LOG_FILE}\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Save Results to Google Drive (unique filename next to notebook)\n",
    "# -------------------------------------------------------------\n",
    "import shutil, datetime\n",
    "import os\n",
    "\n",
    "def save_results_to_notebook_folder(dataset=\"D1-D6\", threshold=\"NA\", refractory=\"NA\"):\n",
    "\n",
    "    # üéØ FORCE directory back to where the notebook is saved.\n",
    "    notebook_dir = \"/content/drive/MyDrive/Colab Notebooks\"\n",
    "\n",
    "    # Temporarily change the directory for accurate saving relative to Drive\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(notebook_dir)\n",
    "\n",
    "    # Create the unique filename\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    threshold_str = str(threshold).replace('.', '_')\n",
    "    refractory_str = str(refractory)\n",
    "    zip_name = f\"Testing_signal_p{timestamp}\"\n",
    "\n",
    "    # The output is saved relative to the new CWD (notebook_dir)\n",
    "    try:\n",
    "        # Note: We are zipping the 'outputs' folder located inside the original repo directory\n",
    "        shutil.make_archive(zip_name, 'zip', original_cwd + '/outputs')\n",
    "        print(f\"‚úÖ Saved archive to notebook folder: {notebook_dir}/{zip_name}.zip\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving archive: {e}\")\n",
    "        print(\"\\nEnsure the source directory 'outputs' exists and contains files.\")\n",
    "\n",
    "    # IMPORTANT: Change directory back to the repository for the next step (Commit to GitHub)\n",
    "    os.chdir(original_cwd)\n",
    "\n",
    "# Example usage:\n",
    "save_results_to_notebook_folder(dataset=\"D2-D6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e93b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 7.1 Connect to github\n",
    "# -------------------------------------------------------------\n",
    "!git config --global user.email \"zachmp1710@gmail.com\"\n",
    "!git config --global user.name \"Zed-080\"\n",
    "\n",
    "import getpass\n",
    "from google.colab import userdata\n",
    "# token = getpass.getpass('GitHub Token:')\n",
    "token = userdata.get(\"COMP_MAJOR_NN_TOKEN\")\n",
    "!git config --global credential.helper store\n",
    "\n",
    "with open('/root/.git-credentials', 'w') as f:\n",
    "    f.write(f\"https://{token}:x-oauth-basic@github.com\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 7.2 Commit Results to GitHub (outputs + metadata)\n",
    "# -------------------------------------------------------------\n",
    "import subprocess, datetime\n",
    "\n",
    "# Define the branch dedicated to storing Colab runs and artifacts\n",
    "# CHANGED to the user's preferred branch name: 'colab-interface'\n",
    "COLAB_BRANCH_NAME = \"colab-interface\"\n",
    "\n",
    "def commit_results(threshold='NA', refractory='NA', script_run=\"main_train.py + main_infer.py\"):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    gpu_info = subprocess.getoutput(\"nvidia-smi --query-gpu=name --format=csv,noheader\")\n",
    "    # Note: Using NA for threshold/refractory in the commit log since they are not passed to this function\n",
    "    threshold_str = str(threshold).replace('.', '_')\n",
    "\n",
    "    commit_message = (\n",
    "        f\"Run at {timestamp} | GPU: {gpu_info} | Scripts: {script_run} | \"\n",
    "        f\"Threshold={threshold_str} | Refractory={refractory}\"\n",
    "    )\n",
    "\n",
    "    # --- 1. Switch to/Create Dedicated Branch (Safe from 'main' conflicts) ---\n",
    "    print(f\"--- Switching to/creating branch: {COLAB_BRANCH_NAME} ---\")\n",
    "    # The -B flag ensures the branch is created if it doesn't exist,\n",
    "    # or reset/switched to if it does exist.\n",
    "    !git checkout -B {COLAB_BRANCH_NAME}\n",
    "\n",
    "    # --- 2. Stage Files and Commit Locally ---\n",
    "    print(\"Staging all output files...\")\n",
    "    !git add outputs/*\n",
    "    !git add NeuralSpikeSorter_Submission.zip\n",
    "    !git add submission_datasets/*\n",
    "\n",
    "    # Commit files locally to the new branch\n",
    "    # --allow-empty lets it run if the files haven't changed\n",
    "    print(\"Creating local commit...\")\n",
    "    !git commit -m \"{commit_message}\" --allow-empty\n",
    "\n",
    "    # --- 3. Push to Remote Branch ---\n",
    "    # FIX: Use --force-with-lease to override the rejection.\n",
    "    # This is necessary the first time a new branch is pushed when the remote HEAD is different.\n",
    "    # We also keep the -u flag to set the upstream tracking.\n",
    "    print(f\"Pushing commit to remote branch: {COLAB_BRANCH_NAME} (using --force-with-lease)\")\n",
    "    !git push -u origin {COLAB_BRANCH_NAME} --force\n",
    "\n",
    "# Example usage:\n",
    "# If your threshold/refractory values are 0.95 and 30 (from the training log):\n",
    "commit_results(threshold=0.95, refractory=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a0ea6",
   "metadata": {},
   "source": [
    "<u><b>Saving output to Drive mount log:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, datetime\n",
    "from google.colab import drive, files  # type: ignore\n",
    "\n",
    "# 1) Ensure Google Drive is mounted\n",
    "if not os.path.isdir('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 2) Define source folder (inside repo) and destination (outside repo in Drive)\n",
    "src_folder = \"NeuralSpikeSorter-2009/submission_datasets\"\n",
    "base_output = \"/content/drive/MyDrive/ColabOutputs/SubmissionDatasets\"\n",
    "os.makedirs(base_output, exist_ok=True)\n",
    "\n",
    "# 3) Create a timestamped archive name\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "zip_name = f\"submission_datasets_{timestamp}\"\n",
    "zip_path = os.path.join(base_output, zip_name)\n",
    "\n",
    "# 4) Create the archive directly in Google Drive\n",
    "shutil.make_archive(zip_path, 'zip', src_folder)\n",
    "print(f\"‚úÖ Saved archive to Drive: {zip_path}.zip\")\n",
    "\n",
    "# 5) Optional: also download to your local machine (uncomment to use)\n",
    "files.download(f\"{zip_path}.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfba0bf0",
   "metadata": {},
   "source": [
    "<u><b>Clean up runtime worksapce:</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a46b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import os\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define repo folder name\n",
    "repo_folder = \"NeuralSpikeSorter-2009\"\n",
    "\n",
    "# Full path to repo\n",
    "repo_path = os.path.join(\"/content\", repo_folder)\n",
    "\n",
    "# Cleanup logic\n",
    "if cwd.endswith(repo_folder):\n",
    "    print(f\"‚úÖ Already inside '{repo_folder}' ‚Äî changing to delete.\")\n",
    "    os.chdir(\"../\")\n",
    "    shutil.rmtree(repo_path)\n",
    "    print(f\"üßπ Removed '{repo_folder}' from workspace.\")\n",
    "elif os.path.exists(repo_path):\n",
    "    shutil.rmtree(repo_path)\n",
    "    print(f\"üßπ Removed '{repo_folder}' from workspace.\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è '{repo_folder}' not found ‚Äî nothing to clean.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
